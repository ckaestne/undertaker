#!/usr/bin/env python
#
#   vampyr - analyzes feature dependencies in Linux source files
#
# Copyright (C) 2011 Christian Dietrich <christian.dietrich@informatik.uni-erlangen.de>
# Copyright (C) 2011-2012 Reinhard Tartler <tartler@informatik.uni-erlangen.de>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import os
import sys

import glob
import logging
import pprint
import tempfile

from os.path import join, dirname

from optparse import OptionParser

sys.path = [join(dirname(sys.path[0]), 'lib', 'python%d.%d' % \
                     (sys.version_info[0], sys.version_info[1]), 'site-packages')] \
                     + sys.path

from vamos.tools import setup_logging, calculate_worklist, check_tool, execute, \
    get_online_processors
from vamos.vampyr.BuildFrameworks import select_framework
from vamos.vampyr.Configuration import Configuration, ExpansionError
from vamos.vampyr.Messages import MessageContainer
from vamos.golem.kbuild import guess_arch_from_filename


def do_checks(options, filename, configs):
    """returns a dictionary with errors"""
    errors = dict()

    print "Checking %d configuration(s):" % len(configs)
    for c in configs:
        # for kconfig, this will automatically try to expand the configuration
        # for bare, this will be a noop
        c.switch_to()

        for tool in options['call']:
            if not hasattr(c, "call_" + tool):
                logging.error(tool + " not supported by this build system")
                continue

            try:
                analyzer = getattr(c, "call_" + tool)
            except:
                raise RuntimeError("Couldn't call analyzer '%s'" % tool)

            try:
                msgs = analyzer(filename)
            except RuntimeError as error:
                logging.error(error)
                continue

            if tool not in errors:
                errors[tool] = MessageContainer()

            reportfilename = c.filename() + '.report.' + tool
            logging.info("%s: detected %d errors with tool '%s'", reportfilename, len(msgs), tool)

            with open(reportfilename, 'w') as reportfile:
                report = set()
                for msg in msgs:
                    # Discard messages from other files
                    if options['exclude_others']:
                        if not filename in msg.location:
                            logging.debug("Discarded error messge (--exclude-others): %s", repr(msg))
                            continue
                    errors[tool].add_message(c, msg)
                    report.add(msg.get_message())
                reportfile.write("\n".join(sorted(report)))

    return errors


def handle_file(options, filename):

    framework = options['framework']
    configs = framework.calculate_configurations(filename)
    if len(configs) == 0:
        logging.error("File %s did not contain any configurations", filename)
        return

    errors = do_checks(options, filename, configs)

    config_dependent_messages = 0
    for c in configs:
        assert(isinstance(c, Configuration))
        total_errors_for_config = 0
        for tool in errors.keys():
            for message in errors[tool]:
                if c in message.in_configurations:
                    total_errors_for_config += 1

        print "%s:\t%d errors" % (str(c), total_errors_for_config)


    if len(configs) == 1 or options['loglevel'] < logging.WARNING:
        format_errors(errors)

    if len(configs) == 1:
        return

    for tool in errors.keys():
        for message in errors[tool]:
            is_configuration_dependent = len(message.in_configurations) < len(configs)
            if is_configuration_dependent:
                print "   Not in all configs: " + message.get_report()
                config_dependent_messages += 1

    print "Found %d configuration dependent errors" % config_dependent_messages


def format_errors(errors):
    for tool in errors.keys():
        if len(errors[tool]) > 0:
            print "  ---- %s: ----" % tool
            print "\n\n".join([x.get_report() for x in errors[tool]])
            print "  -------------"


def analyze_variability(source_files, options):
    bf = options['framework']

    # If there is no fixed architecture, then have to guess the 'best'
    # architecture for each file individually. However, the user might
    # request checking for files for which the best architecture may
    # vary. Therefore, we need to group up the worklists by their
    # architecture, as we need to run undertaker's dead analysis on each
    # architecture individually.
    wl_dict = dict()
    reset_arch = False
    for f in source_files:
        if not options.has_key('arch') or not options['arch']:
            # NB: In that case we have to explicitly unset the architecture
            #     in the buildframework each time we analyze a new file!
            logging.info("Guessing architecture for %s", f)
            arch, _ = guess_arch_from_filename(f)
            reset_arch = True
        else:
            arch = options['arch']
        if not wl_dict.has_key(arch):
            wl_dict[arch] = set()
        wl_dict[arch].add(f)
        for dead in glob.glob("%s*dead" % f):
            logging.debug("Removing stale defect file %s", dead)
            os.unlink(dead)

    for arch in wl_dict.keys():
        if not os.path.exists('models/%s.model' % arch):
            logging.error("No model found for architecture %s", arch)
            continue
        with tempfile.NamedTemporaryFile() as tmpfile:
            tmpfile.write("\n".join(wl_dict[arch]))
            tmpfile.flush()
            execute("undertaker -j dead -m models/%s.model -t %d -b %s" \
                        % (arch, options['threads'], tmpfile.name),
                    failok=False)

    for f in source_files:
        logging.info("Analyzing %s", f)
        if reset_arch:
            bf.options['arch'], bf.options['subarch'] = None, None
        results = bf.analyze_configuration_coverage(f)
        # add dead/undead statistics
        results['dead blocks']   = [x.split(".")[-4] for x in glob.glob("%s*.dead" % f)]
        results['undead blocks'] = [x.split(".")[-4] for x in glob.glob("%s*.undead" % f)]
        reportname = f + ".coverage"
        if 'arch' in options and options['arch']:
            reportname += '.' + options['arch']
        with open(reportname, "w+") as fd:
            fd.write(pprint.pformat(results))
            print "coverage report dumped to " + reportname

        print "%s: Covered %d/%d blocks, %d/%d lines, %d deads" % \
            (f, len(results['blocks_covered']), len(results['blocks_total']),
             results['lines_covered'], results['lines_total'],
             len(results["dead blocks"]))

        if len(results['blocks_covered'] - results['blocks_total']) > 0:
            logging.error("File %s covered more blocks than available: %d > %d",
                          f, len(results['blocks_covered']), len(results['blocks_total']))

        if results['lines_covered'] > results['lines_total']:
            logging.error("File %s covered more lines than available: %d > %d",
                          f, results['lines_covered'], results['lines_total'])

        for dead in results['dead blocks']:
            if dead in results['blocks_covered']:
                logging.error("Block %s in %s is dead but still covered", dead, f)


def expand_partial_configurations(framework, source_files):
    success = set()
    fail = set()

    for f in source_files:
        # santity check for allowing 'golem sched/kernel.c.config*'
        # without stumbling over .expanded files
        if f.endswith('.expanded'):
            logging.info("Ignoring %s", f)
            continue

        configs = framework.calculate_configurations(f)
        logging.info("%s: processing %d configurations", f, len(configs))

        for config in configs:
            logging.debug("Checking Config %s", config.filename())
            try:
                config.expand(verify=True)
                success.add(config)
                logging.info("OK:   " + config.filename())
            except ExpansionError:
                fail.add(config)
                logging.info("FAIL: " + config.filename())

    return (success, fail)


def main():
    # this method has too many branches and statements
    # pylint: disable=R0912
    # pylint: disable=R0915
    parser = OptionParser(usage="%prog [options] <filename>")
    parser.add_option('-v', '--verbose', dest='verbose', action='count',
                      help="increase verbosity (specify multiple times for more)")
    parser.add_option("-O", '--args', dest='args', action='append', type="string",
                      default=[],
                      help="add options to called programs, like -Osparse,-Wall")
    parser.add_option("-C", '--call', dest='call', action='append', type="string",
                      default=[],
                      help="add static analyzers to call stack, like -C gcc -C sparse")
    parser.add_option("", '--exclude-others', dest='exclude_others', action='store_true',
                      default=False,
                      help="suppress warnings in '#included' source files")
    parser.add_option("-f", '--framework', dest='framework', action='store', type="string",
                      default=None,
                      help="select build framework (one of 'bare', 'kbuild')")
    parser.add_option('-a', '--analyze', dest='do_analyze', action='store_true', default=False,
                      help="analyze variability")
    parser.add_option('-e', '--expand', dest='do_expansion', action='store_true',
                      help="try to expand the given partial configuration")
    parser.add_option('-b', '--batch', dest='batch_mode', action='store_true', default=False,
                      help="operate in batch mode, read filenames from given worklists")
    parser.add_option('-t', '--threads', dest='threads', action='store', type='int',
                      default=0,
                      help="Number of parallel threads for undertaker dead analysis")
    parser.add_option('-c', '--config', dest='configfile',
                      help="Analyze a given configuration in config.h format")

    (opts, args) = parser.parse_args()

    setup_logging(opts.verbose)

    if len(args) < 1:
        print "Vampyr - VAMOS Variability aware static analyzer driver\n"
        parser.print_help()
        sys.exit(1)

    options = { 'args': {},
                'threads': get_online_processors() if opts.threads == 0 else opts.threads,
                'exclude_others': opts.exclude_others,
                'loglevel': logging.getLogger().getEffectiveLevel()}

    for arg in opts.args:
        if not "," in arg:
            logging.critical("Couldn't parse --args argument: %s", arg)
            sys.exit(-1)
        (key, value) = arg.split(",", 1)
        options['args'][key] = value

    options['framework'] = select_framework(opts.framework, options)

    if opts.configfile:
        if os.path.exists(opts.configfile):
            logging.info("Restricting Analysis to %s", opts.configfile)
            options['configfile'] = opts.configfile
        else:
            logging.error("Configfile %s does not exist, aborting")
            sys.exit(1)

    if opts.do_analyze:
        source_files = calculate_worklist(args, opts.batch_mode)
        analyze_variability(source_files, options)
        sys.exit(0)

    if opts.do_expansion:
        bf = options['framework']
        worklist = calculate_worklist(args, batch_mode=opts.batch_mode)
        success, fail = expand_partial_configurations(bf, worklist)
        print "Total OK: %d, Total FAIL: %d" % (len(success), len(fail))
        sys.exit(0)

    options['call'] = []

    if len(opts.call) == 0:
        print "Please use the -C option to specify what static analyzers to use"
        sys.exit(1)

    for call in opts.call:
        if ',' in call:
            options['call'].extend(call.split(","))
        else:
            options['call'].append(call)

        # check if the specified tools are available in the default search path
        if call == 'gcc' and not check_tool('gcc --version'):
            sys.exit(1)

        if call == 'sparse' and not check_tool('sparse'):
            sys.exit(1)

        # add default options if not set by user
        if (call == 'gcc' and 'gcc' not in options['args']):
            options['args']['gcc'] = "-Wall -Wextra"

        if (call == 'sparse' and 'sparse' not in options['args']):
            options['args']['sparse'] = "-Wsparse-all"

    for tool in ("fakecc", "make --version"):
        if not check_tool(tool):
            sys.exit(1)

    for fn in calculate_worklist(args, batch_mode=opts.batch_mode):
        handle_file(options, fn)


if __name__ == "__main__":
    main()
